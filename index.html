<html>

<head>
	<meta charset="UTF-8">
	<title>TM_AR</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<!-- <meta name="viewport" content="initial-scale=1, maximum-scale=1, user-scalable=no, width=device-width, shrink-to-fit=yes"> -->
	<link rel="icon" href="multicore_logo.ico" sizes="32x32">
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
	<link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
	<h2 id="titlex" style="width:100%; padding:10px; text-align: center; display:none">TM_AR</h2>
	<div id="cam" style="width:100%; height:100%; padding-top:100px; text-align: center">
		<button id="img_bkg"  style="width:80%; font-size:64px" onclick="init()">Teachable <br>Machine</button>
	</div>

	<div id="webcam-container" style="width:100%; text-align: center;"></div>
	<div id="label-container" style="width:100%; text-align: center;"></div>

	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
	<script type="text/javascript">
		// More API functions here:
		// https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image
		// the link to your model provided by Teachable Machine export panel
		
		let model_no = "22926JMSE";
		const URL = "https://teachablemachine.withgoogle.com/models/"+model_no+"/";

		let model, webcam, labelContainer, maxPredictions;

		// Load the image model and setup the webcam
		async function init() {
			const modelURL = URL + "model.json";
			const metadataURL = URL + "metadata.json";

			// load the model and metadata
			// Refer to tmImage.loadFromFiles() in the API to support files from a file picker
			// or files from your local hard drive
			// Note: the pose library adds "tmImage" object to your window (window.tmImage)
			
			model = await tmImage.load(modelURL, metadataURL);
			maxPredictions = model.getTotalClasses();

			//console.log("maxPredictions: " + maxPredictions);

			let camW = window.innerWidth;
			if(camW>400){
				camW = 400;
			}

			// Convenience function to setup a webcam
			const flip = true; // whether to flip the webcam
			webcam = new tmImage.Webcam(camW, camW, flip); // width, height, flip
			//webcam = new tmImage.Webcam(300, 300, flip); // width, height, flip
			//await webcam.setup(); // request access to the webcam
			//await webcam.setup({facingMode: "user"});
			await webcam.setup({facingMode: "environment"});
			await webcam.play();
			window.requestAnimationFrame(loop);

			// append elements to the DOM
			document.getElementById("webcam-container").appendChild(webcam.canvas);
			labelContainer = document.getElementById("label-container");
			for (let i = 0; i < maxPredictions; i++) { // and class labels
				labelContainer.appendChild(document.createElement("div"));
			}
			
			$("#titlex").show();
			$("#cam").hide();
		}

		async function loop() {
			webcam.update(); // update the webcam frame
			await predict();
			window.requestAnimationFrame(loop);
		}

    let st = 0;
		// run the webcam image through the image model
		async function predict() {
			// predict can take in an image, video or canvas html element
			const prediction = await model.predict(webcam.canvas);
			
			//maxPredictions = prediction.length;
			//console.log(maxPredictions);
			//console.log(prediction);

			let sid = "";
			let cv = 0;
			for (let i = 0; i < maxPredictions; i++) {
				
				//let t1 = parseInt(prediction[i].className);
				//let t2 = prediction[i].probability.toFixed(2);
				let t1 = prediction[i].className;
				let t2 = prediction[i].probability.toFixed(2);
				const classPrediction =	t1 + ": " + t2;
				
				
				//-------------------------
				if(prediction[i].probability>0.99){
				  labelContainer.childNodes[i].innerHTML = "<h5>"+classPrediction+"</h5>";

					if(t2>=cv){
						cv = t2;
						sid = t1;
					}

			  } else {
					labelContainer.childNodes[i].innerHTML = "";
				}
			}

      //-------------------------
      if(sid=="person"){
				if(st==0){
					st = 1;
					//console.log(sid);
					//$("#frm").attr("src", "view.html?pn="+sid);
					//$("#frm").show();
					//$("#frm").fadeIn( "slow" );

					$("#frm").attr("src", "http://processing.org");
					$("#frm").show();
					$("#b1").show();
					//$("#frm").fadeIn( "slow" );

			  }
		  } else {
				st = 0; 
			}

		}
    
		function startx(){
				st = 0;
			  $("#frm").hide();
				$("#frm").attr("src", "");
				$("#b1").hide();
				setTimeout( () => { 
					st = 0; 
				} , "3000");
		}

		// document.addEventListener('touchstart', (event) => {
		// 	if (event.touches && event.touches.length > 1) {  // 禁止多指觸控
		// 		event.preventDefault();
		// 	}
		// }, { passive: false });

	</script>
	<iframe id="frm" src="" style="display:none; width:100vw; height:100vh; position:fixed; left:0px; top:0px;"></iframe>
	<button type="button" class="btn btn-info" id="b1" onclick="startx()" style="position:absolute; top:0px; right:0px; margin:10px; background-color: black; color:white; display:none">X</button>
</body>

</html>
